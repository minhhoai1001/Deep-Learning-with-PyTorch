{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Real-world data representation using tensors\n",
    "This chapter covers\n",
    "* Representing real-world data as PyTorch tensors\n",
    "* Working with a range of data types\n",
    "* Loading data from a file\n",
    "* Converting data to tensors\n",
    "* Shaping tensors so they can be used as inputs for neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Working with images\n",
    "An image is represented as a collection of scalars arranged in a regular grid with a\n",
    "height and a width (in pixels). We might have a single scalar per grid point (the\n",
    "pixel), which would be represented as a grayscale image; or multiple scalars per grid\n",
    "point, which would typically represent different colors, as we saw in the previous chap-\n",
    "ter, or different features like depth from a depth camera.\n",
    "\n",
    "Scalars representing values at individual pixels are often encoded using 8-bit inte-\n",
    "gers, as in consumer cameras. In medical, scientific, and industrial applications, it is\n",
    "not unusual to find higher numerical precision, such as 12-bit or 16-bit. This allows a\n",
    "wider range or increased sensitivity in cases where the pixel encodes information\n",
    "about a physical property, like bone density, temperature, or depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Adding color channels\n",
    "We mentioned colors earlier. There are several ways to encode colors into numbers. 1\n",
    "The most common is RGB, where a color is defined by three numbers representing\n",
    "the intensity of red, green, and blue. We can think of a color channel as a grayscale\n",
    "intensity map of only the color in question, similar to what you’d see if you looked at\n",
    "the scene in question using a pair of pure red sunglasses. Figure 4.1 shows a rainbow,\n",
    "where each of the RGB channels captures a certain portion of the spectrum (the fig-\n",
    "ure is simplified, in that it elides things like the orange and yellow bands being repre-\n",
    "sented as a combination of red and green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Loading an image file\n",
    "Images come in several different file formats, but luckily there are plenty of ways to\n",
    "load images in Python. Let’s start by loading a PNG image using the imageio module\n",
    "(code/p1ch4/1_image_dog.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "\n",
    "img_arr = imageio.imread('./data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Changing the layout\n",
    "We can use the tensor’s `permute` method with the old dimensions for each new dimension to get to an appropriate layout. Given an input tensor H × W × C as obtained previously, we get a proper layout by having channel 2 first and then channels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve seen this previously, but note that this operation does not make a copy of the\n",
    "tensor data. Instead, `out` uses the same underlying storage as `img` and only plays with\n",
    "the size and stride information at the tensor level. This is convenient because the\n",
    "operation is very cheap; but just as a heads-up: changing a pixel in `img` will lead to a\n",
    "change in `out`.\n",
    "\n",
    "As a slightly more efficient alternative to using `stack` to build up the tensor, we can preallocate a tensor of appropriate size and fill it with images loaded from a directory, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that our batch will consist of three RGB images 256 pixels in height and\n",
    "256 pixels in width. Notice the type of the tensor: we’re expecting each color to be represented as an 8-bit integer, as in most photographic formats from standard consumer\n",
    "cameras. We can now load all PNG images from an input directory and store them in\n",
    "the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = './data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "            if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3] # Here we keep only the first three channels.\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Normalizing the data\n",
    "We mentioned earlier that neural networks usually work with floating-point tensors as\n",
    "their input. Neural networks exhibit the best training performance when the input\n",
    "data ranges roughly from 0 to 1, or from -1 to 1 (this is an effect of how their building\n",
    "blocks are defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to compute the mean and standard deviation of the input data\n",
    "and scale it so that the output has zero mean and unit standard deviation across each\n",
    "channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform several other operations on inputs, such as geometric transformations like rotations, scaling, and cropping. These may help with training or may be\n",
    "required to make an arbitrary input conform to the input requirements of a network,\n",
    "like the size of the image. We will stumble on quite a few of these strategies in section\n",
    "12.6. For now, just remember that you have image-manipulation options available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 3D images: Volumetric data\n",
    "We’ve learned how to load and represent 2D images, like the ones we take with a camera.\n",
    "In some contexts, such as medical imaging applications involving, say, CT (computed\n",
    "tomography) scans, we typically deal with sequences of images stacked along the head-\n",
    "to-foot axis, each corresponding to a slice across the human body.\n",
    "\n",
    "CTs have only a single intensity channel, similar to a grayscale image. This means\n",
    "that often, the channel dimension is left out in native data formats; so, similar to the\n",
    "last section, the raw data typically has three dimensions. By stacking individual 2D\n",
    "slices into a 3D tensor, we can build volumetric data representing the 3D anatomy of a\n",
    "subject. Unlike what we saw in figure 4.1, the extra dimension in figure 4.2 represents\n",
    "an offset in physical space, rather than a particular band of the visible spectrum.\n",
    "\n",
    "![](images/4.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Loading a specialized format\n",
    "Let’s load a sample CT scan using the volread function in the imageio module, which\n",
    "takes a directory as an argument and assembles all Digital Imaging and Communi-\n",
    "cations in Medicine (DICOM) files 2 in a series in a NumPy 3D array (code/p1ch4/\n",
    "2_volumetric_ct.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%34/99 files (34.3%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 24/99  (24.252/99  (52.579/99  (79.899/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "dir_path = \"./data/p1ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was true in section 4.1.3, the layout is different from what PyTorch expects, due to\n",
    "having no channel information. So we’ll have to make room for the `channel` dimension using `unsqueeze` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could assemble a 5D dataset by stacking multiple volumes along the\n",
    "batch direction, just as we did in the previous section. We’ll see a lot more CT data in\n",
    "part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Representing tabular data\n",
    "The simplest form of data we’ll encounter on a machine learning job is sitting in a\n",
    "spreadsheet, CSV file, or database. Whatever the medium, it’s a table containing one\n",
    "row per sample (or record), where columns contain one piece of information about\n",
    "our sample.\n",
    "\n",
    "Columns may contain numerical values, like temperatures at specific locations; or\n",
    "labels, like a string expressing an attribute of the sample, like “blue.” Therefore, tabu-\n",
    "lar data is typically not homogeneous: different columns don’t have the same type. We\n",
    "might have a column showing the weight of apples and another encoding their color\n",
    "in a label.\n",
    "\n",
    "PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is typically encoded as a number, typically floating-point (though integer types and Boolean are supported as well). This numeric encoding is deliberate, since neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Using a real-world dataset\n",
    "\n",
    "Our first job as deep learning practitioners is to encode heterogeneous, real-world\n",
    "data into a tensor of floating-point numbers, ready for consumption by a neural net-\n",
    "work. A large number of tabular datasets are freely available on the internet; see, for\n",
    "instance, https://github.com/caesar0301/awesome-public-datasets. Let’s start with\n",
    "something fun: wine! The Wine Quality dataset is a freely available table containing\n",
    "chemical characterizations of samples of vinho verde, a wine from north Portugal,\n",
    "together with a sensory quality score. The dataset for white wines can be downloaded\n",
    "here: http://mng.bz/90Ol. For convenience, we also created a copy of the dataset on\n",
    "the Deep Learning with PyTorch Git repository, under data/p1ch4/tabular-wine.\n",
    "\n",
    "A possible machine learning task on this dataset is predicting the quality score from\n",
    "chemical characterization alone. Don’t worry, though; machine learning is not going\n",
    "to kill wine tasting anytime soon. We have to get the training data from somewhere! As\n",
    "we can see in figure 4.3, we’re hoping to find a relationship between one of the chem-\n",
    "ical columns in our data and the quality column. Here, we’re expecting to see quality\n",
    "increase as sulfur decreases.\n",
    "\n",
    "![](images/4.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Loading a wine data tensor\n",
    "Before we can get to that, however, we need to be able to examine the data in a more\n",
    "usable way than opening the file in a text editor. Let’s see how we can load the data\n",
    "using Python and then turn it into a PyTorch tensor. Python offers several options for\n",
    "quickly loading a CSV file. Three popular options are\n",
    "* The csv module that ships with Python\n",
    "* NumPy\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "wine_path = \"./data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just prescribe what the type of the 2D array should be (32-bit floating-point),\n",
    "the delimiter used to separate values in each row, and the fact that the first line should\n",
    "not be read since it contains the column names. Let’s check that all the data has been\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and proceed to convert the NumPy array to a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Representing scores\n",
    "We could treat the score as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess the label from the chemical analysis in a classification task. In both approaches, we will typically remove the\n",
    "score from the tensor of input data and keep it in a separate tensor, so that we can use\n",
    "the score as the ground truth without it being input to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]  # Selects all rows and all columns except the last\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]  # Selects all rows and the last column\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to transform the `target` tensor in a tensor of labels, we have two options,\n",
    "depending on the strategy or what we use the categorical data for. One is simply to\n",
    "treat labels as an integer vector of scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()  # Selects all rows and the last column\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If targets were string labels, like `wine color`, assigning an integer number to each string would let us follow the same approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 One-hot encoding\n",
    "The other approach is to build a *one-hot encoding* of the scores: that is, encode each of\n",
    "the 10 scores in a vector of 10 elements, with all elements set to 0 but one, at a differ-\n",
    "ent index for each score.\n",
    "\n",
    "We can achieve one-hot encoding using the `scatter_` method, which fills the tensor with values from a source tensor along the indices provided as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see what `scatter_` does. First, we notice that its name ends with an underscore.\n",
    "As you learned in the previous chapter, this is a convention in PyTorch that indicates\n",
    "the method will not return a new tensor, but will instead modify the tensor in place.\n",
    "The arguments for `scatter_` are as follows:\n",
    "* The dimension along which the following two arguments are specified\n",
    "* A column tensor indicating the indices of the elements to scatter\n",
    "* A tensor containing the elements to scatter or a single scalar to scatter (1, in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument of `scatter_` , the index tensor, is required to have the same\n",
    "number of dimensions as the tensor we scatter into. Since `target_onehot` has two\n",
    "dimensions (4,898 × 10), we need to add an extra dummy dimension to target using\n",
    "`unsqueeze`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to `unsqueeze` adds a `singleton` dimension, from a 1D tensor of 4,898 elements\n",
    "to a 2D tensor of size (4,898 × 1), without changing its contents—no extra elements\n",
    "are added; we just decided to use an extra index to access the elements. That is, we\n",
    "access the first element of `target` as `target[0]` and the first element of its\n",
    "unsqueezed counterpart as `target_unsqueezed[0,0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 When to categorize\n",
    "Now we have seen ways to deal with both continuous and categorical data. You may wonder what the deal is with the ordinal case discussed in the earlier sidebar. There is no general recipe for it; most commonly, such data is either treated as categorical (losing the ordering part, and hoping that maybe our model will pick it up during training if we only have a few categories) or continuous (introducing an arbitrary notion of distance). We will do the latter for the weather situation in figure 4.5. We summarize our data mapping in a small flow chart in figure 4.4.\n",
    "\n",
    "![](images/4.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go back to our data tensor, containing the 11 variables associated with the chemical\n",
    "analysis. We can use the functions in the PyTorch Tensor API to manipulate our data in\n",
    "tensor form. Let’s first obtain the **mean** and **standard deviations** for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `dim=0` indicates that the reduction is performed along dimension 0. At\n",
    "this point, we can normalize the data by subtracting the mean and dividing by the\n",
    "standard deviation, which helps with the learning process (we’ll discuss this in more\n",
    "detail in chapter 5, in section 5.4.4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.6 Finding thresholds\n",
    "Next, let’s start to look at the data with an eye to seeing if there is an easy way to tell\n",
    "good and bad wines apart at a glance. First, we’re going to determine which rows in\n",
    "`target` correspond to a score less than or equal to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3  ## PyTorch also provides comparison functions, here torch.le(target, 3), but using operators seems to be a good standard.\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only 20 of the `bad_indexes` entries are set to `True` ! By using a feature in\n",
    "PyTorch called *advanced indexing*, we can use a tensor with data type `torch.bool` to\n",
    "index the `data` tensor. This will essentially filter data to be only items (or rows) corresponding to `True` in the indexing tensor. The `bad_indexes` tensor has the same shape\n",
    "as `target` , with values of `False` or `True` depending on the outcome of the comparison\n",
    "between our threshold and each element in the original `target` tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
