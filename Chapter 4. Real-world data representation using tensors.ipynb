{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Real-world data representation using tensors\n",
    "This chapter covers\n",
    "* Representing real-world data as PyTorch tensors\n",
    "* Working with a range of data types\n",
    "* Loading data from a file\n",
    "* Converting data to tensors\n",
    "* Shaping tensors so they can be used as inputs for neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Working with images\n",
    "An image is represented as a collection of scalars arranged in a regular grid with a\n",
    "height and a width (in pixels). We might have a single scalar per grid point (the\n",
    "pixel), which would be represented as a grayscale image; or multiple scalars per grid\n",
    "point, which would typically represent different colors, as we saw in the previous chap-\n",
    "ter, or different features like depth from a depth camera.\n",
    "\n",
    "Scalars representing values at individual pixels are often encoded using 8-bit inte-\n",
    "gers, as in consumer cameras. In medical, scientific, and industrial applications, it is\n",
    "not unusual to find higher numerical precision, such as 12-bit or 16-bit. This allows a\n",
    "wider range or increased sensitivity in cases where the pixel encodes information\n",
    "about a physical property, like bone density, temperature, or depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Adding color channels\n",
    "We mentioned colors earlier. There are several ways to encode colors into numbers. 1\n",
    "The most common is RGB, where a color is defined by three numbers representing\n",
    "the intensity of red, green, and blue. We can think of a color channel as a grayscale\n",
    "intensity map of only the color in question, similar to what you’d see if you looked at\n",
    "the scene in question using a pair of pure red sunglasses. Figure 4.1 shows a rainbow,\n",
    "where each of the RGB channels captures a certain portion of the spectrum (the fig-\n",
    "ure is simplified, in that it elides things like the orange and yellow bands being repre-\n",
    "sented as a combination of red and green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Loading an image file\n",
    "Images come in several different file formats, but luckily there are plenty of ways to\n",
    "load images in Python. Let’s start by loading a PNG image using the imageio module\n",
    "(code/p1ch4/1_image_dog.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "\n",
    "img_arr = imageio.imread('./data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Changing the layout\n",
    "We can use the tensor’s `permute` method with the old dimensions for each new dimension to get to an appropriate layout. Given an input tensor H × W × C as obtained previously, we get a proper layout by having channel 2 first and then channels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve seen this previously, but note that this operation does not make a copy of the\n",
    "tensor data. Instead, `out` uses the same underlying storage as `img` and only plays with\n",
    "the size and stride information at the tensor level. This is convenient because the\n",
    "operation is very cheap; but just as a heads-up: changing a pixel in `img` will lead to a\n",
    "change in `out`.\n",
    "\n",
    "As a slightly more efficient alternative to using `stack` to build up the tensor, we can preallocate a tensor of appropriate size and fill it with images loaded from a directory, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that our batch will consist of three RGB images 256 pixels in height and\n",
    "256 pixels in width. Notice the type of the tensor: we’re expecting each color to be represented as an 8-bit integer, as in most photographic formats from standard consumer\n",
    "cameras. We can now load all PNG images from an input directory and store them in\n",
    "the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = './data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "            if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3] # Here we keep only the first three channels.\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Normalizing the data\n",
    "We mentioned earlier that neural networks usually work with floating-point tensors as\n",
    "their input. Neural networks exhibit the best training performance when the input\n",
    "data ranges roughly from 0 to 1, or from -1 to 1 (this is an effect of how their building\n",
    "blocks are defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to compute the mean and standard deviation of the input data\n",
    "and scale it so that the output has zero mean and unit standard deviation across each\n",
    "channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform several other operations on inputs, such as geometric transformations like rotations, scaling, and cropping. These may help with training or may be\n",
    "required to make an arbitrary input conform to the input requirements of a network,\n",
    "like the size of the image. We will stumble on quite a few of these strategies in section\n",
    "12.6. For now, just remember that you have image-manipulation options available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 3D images: Volumetric data\n",
    "We’ve learned how to load and represent 2D images, like the ones we take with a camera.\n",
    "In some contexts, such as medical imaging applications involving, say, CT (computed\n",
    "tomography) scans, we typically deal with sequences of images stacked along the head-\n",
    "to-foot axis, each corresponding to a slice across the human body.\n",
    "\n",
    "CTs have only a single intensity channel, similar to a grayscale image. This means\n",
    "that often, the channel dimension is left out in native data formats; so, similar to the\n",
    "last section, the raw data typically has three dimensions. By stacking individual 2D\n",
    "slices into a 3D tensor, we can build volumetric data representing the 3D anatomy of a\n",
    "subject. Unlike what we saw in figure 4.1, the extra dimension in figure 4.2 represents\n",
    "an offset in physical space, rather than a particular band of the visible spectrum.\n",
    "\n",
    "![](images/4.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Loading a specialized format\n",
    "Let’s load a sample CT scan using the volread function in the imageio module, which\n",
    "takes a directory as an argument and assembles all Digital Imaging and Communi-\n",
    "cations in Medicine (DICOM) files 2 in a series in a NumPy 3D array (code/p1ch4/\n",
    "2_volumetric_ct.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%41/99 files (41.4%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 23/99  (23.250/99  (50.576/99  (76.899/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "dir_path = \"./data/p1ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was true in section 4.1.3, the layout is different from what PyTorch expects, due to\n",
    "having no channel information. So we’ll have to make room for the `channel` dimension using `unsqueeze` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could assemble a 5D dataset by stacking multiple volumes along the\n",
    "batch direction, just as we did in the previous section. We’ll see a lot more CT data in\n",
    "part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Representing tabular data\n",
    "The simplest form of data we’ll encounter on a machine learning job is sitting in a\n",
    "spreadsheet, CSV file, or database. Whatever the medium, it’s a table containing one\n",
    "row per sample (or record), where columns contain one piece of information about\n",
    "our sample.\n",
    "\n",
    "Columns may contain numerical values, like temperatures at specific locations; or\n",
    "labels, like a string expressing an attribute of the sample, like “blue.” Therefore, tabu-\n",
    "lar data is typically not homogeneous: different columns don’t have the same type. We\n",
    "might have a column showing the weight of apples and another encoding their color\n",
    "in a label.\n",
    "\n",
    "PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is typically encoded as a number, typically floating-point (though integer types and Boolean are supported as well). This numeric encoding is deliberate, since neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Using a real-world dataset\n",
    "\n",
    "Our first job as deep learning practitioners is to encode heterogeneous, real-world\n",
    "data into a tensor of floating-point numbers, ready for consumption by a neural net-\n",
    "work. A large number of tabular datasets are freely available on the internet; see, for\n",
    "instance, https://github.com/caesar0301/awesome-public-datasets. Let’s start with\n",
    "something fun: wine! The Wine Quality dataset is a freely available table containing\n",
    "chemical characterizations of samples of vinho verde, a wine from north Portugal,\n",
    "together with a sensory quality score. The dataset for white wines can be downloaded\n",
    "here: http://mng.bz/90Ol. For convenience, we also created a copy of the dataset on\n",
    "the Deep Learning with PyTorch Git repository, under data/p1ch4/tabular-wine.\n",
    "\n",
    "A possible machine learning task on this dataset is predicting the quality score from\n",
    "chemical characterization alone. Don’t worry, though; machine learning is not going\n",
    "to kill wine tasting anytime soon. We have to get the training data from somewhere! As\n",
    "we can see in figure 4.3, we’re hoping to find a relationship between one of the chem-\n",
    "ical columns in our data and the quality column. Here, we’re expecting to see quality\n",
    "increase as sulfur decreases.\n",
    "\n",
    "![](images/4.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Loading a wine data tensor\n",
    "Before we can get to that, however, we need to be able to examine the data in a more\n",
    "usable way than opening the file in a text editor. Let’s see how we can load the data\n",
    "using Python and then turn it into a PyTorch tensor. Python offers several options for\n",
    "quickly loading a CSV file. Three popular options are\n",
    "* The csv module that ships with Python\n",
    "* NumPy\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "wine_path = \"./data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just prescribe what the type of the 2D array should be (32-bit floating-point),\n",
    "the delimiter used to separate values in each row, and the fact that the first line should\n",
    "not be read since it contains the column names. Let’s check that all the data has been\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and proceed to convert the NumPy array to a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Representing scores\n",
    "We could treat the score as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess the label from the chemical analysis in a classification task. In both approaches, we will typically remove the\n",
    "score from the tensor of input data and keep it in a separate tensor, so that we can use\n",
    "the score as the ground truth without it being input to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]  # Selects all rows and all columns except the last\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]  # Selects all rows and the last column\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to transform the `target` tensor in a tensor of labels, we have two options,\n",
    "depending on the strategy or what we use the categorical data for. One is simply to\n",
    "treat labels as an integer vector of scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()  # Selects all rows and the last column\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If targets were string labels, like `wine color`, assigning an integer number to each string would let us follow the same approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 One-hot encoding\n",
    "The other approach is to build a *one-hot encoding* of the scores: that is, encode each of\n",
    "the 10 scores in a vector of 10 elements, with all elements set to 0 but one, at a differ-\n",
    "ent index for each score.\n",
    "\n",
    "We can achieve one-hot encoding using the `scatter_` method, which fills the tensor with values from a source tensor along the indices provided as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see what `scatter_` does. First, we notice that its name ends with an underscore.\n",
    "As you learned in the previous chapter, this is a convention in PyTorch that indicates\n",
    "the method will not return a new tensor, but will instead modify the tensor in place.\n",
    "The arguments for `scatter_` are as follows:\n",
    "* The dimension along which the following two arguments are specified\n",
    "* A column tensor indicating the indices of the elements to scatter\n",
    "* A tensor containing the elements to scatter or a single scalar to scatter (1, in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument of `scatter_` , the index tensor, is required to have the same\n",
    "number of dimensions as the tensor we scatter into. Since `target_onehot` has two\n",
    "dimensions (4,898 × 10), we need to add an extra dummy dimension to target using\n",
    "`unsqueeze`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to `unsqueeze` adds a `singleton` dimension, from a 1D tensor of 4,898 elements\n",
    "to a 2D tensor of size (4,898 × 1), without changing its contents—no extra elements\n",
    "are added; we just decided to use an extra index to access the elements. That is, we\n",
    "access the first element of `target` as `target[0]` and the first element of its\n",
    "unsqueezed counterpart as `target_unsqueezed[0,0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 When to categorize\n",
    "Now we have seen ways to deal with both continuous and categorical data. You may wonder what the deal is with the ordinal case discussed in the earlier sidebar. There is no general recipe for it; most commonly, such data is either treated as categorical (losing the ordering part, and hoping that maybe our model will pick it up during training if we only have a few categories) or continuous (introducing an arbitrary notion of distance). We will do the latter for the weather situation in figure 4.5. We summarize our data mapping in a small flow chart in figure 4.4.\n",
    "\n",
    "![](images/4.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go back to our data tensor, containing the 11 variables associated with the chemical\n",
    "analysis. We can use the functions in the PyTorch Tensor API to manipulate our data in\n",
    "tensor form. Let’s first obtain the **mean** and **standard deviations** for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `dim=0` indicates that the reduction is performed along dimension 0. At\n",
    "this point, we can normalize the data by subtracting the mean and dividing by the\n",
    "standard deviation, which helps with the learning process (we’ll discuss this in more\n",
    "detail in chapter 5, in section 5.4.4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.6 Finding thresholds\n",
    "Next, let’s start to look at the data with an eye to seeing if there is an easy way to tell\n",
    "good and bad wines apart at a glance. First, we’re going to determine which rows in\n",
    "`target` correspond to a score less than or equal to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3  ## PyTorch also provides comparison functions, here torch.le(target, 3), but using operators seems to be a good standard.\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only 20 of the `bad_indexes` entries are set to `True` ! By using a feature in\n",
    "PyTorch called *advanced indexing*, we can use a tensor with data type `torch.bool` to\n",
    "index the `data` tensor. This will essentially filter data to be only items (or rows) corresponding to `True` in the indexing tensor. The `bad_indexes` tensor has the same shape\n",
    "as `target` , with values of `False` or `True` depending on the outcome of the comparison\n",
    "between our threshold and each element in the original `target` tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the new `bad_data` tensor has 20 rows, the same as the number of rows with\n",
    "`True` in the `bad_indexes` tensor. It retains all 11 columns. Now we can start to get\n",
    "information about wines grouped into good, middling, and bad categories. Let’s take\n",
    "the `.mean()` of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target<=3]\n",
    "mid_data = data[(target>3) & (target<7)] # For Boolean NumPy arrays and PyTorch tensors, the & operator does a logical “and” operation.\n",
    "good_data = data[target>=7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get the indexes where the total sulfur dioxide column is below the midpoint we\n",
    "calculated earlier, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:,6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got around 2,000 wines right! Since we predicted 2,700 wines, this gives us a 74%\n",
    "chance that if we predict a wine to be high quality, it actually is. Unfortunately, there\n",
    "are 3,200 good wines, and we only identified 61% of them. Well, we got what we\n",
    "signed up for; that’s barely better than random! Of course, this is all very naive: we\n",
    "know for sure that multiple variables contribute to wine quality, and the relationships\n",
    "between the values of these variables and the outcome (which could be the actual\n",
    "score, rather than a binarized version of it) is likely more complicated than a simple\n",
    "threshold on a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Working with time series\n",
    "Going back to the wine dataset, we could have had a “year” column that allowed us\n",
    "to look at how wine quality evolved year after year. Unfortunately, we don’t have such\n",
    "data at hand, but we’re working hard on manually collecting the data samples, bottle\n",
    "by bottle. (Stuff for our second edition.) In the meantime, we’ll switch to another\n",
    "interesting dataset: data from a Washington, D.C., bike-sharing system reporting the\n",
    "hourly count of rental bikes in 2011–2012 in the Capital Bikeshare system, along with\n",
    "weather and seasonal information (available here: http://mng.bz/jgOx). Our goal\n",
    "will be to take a flat, 2D dataset and transform it into a 3D one, as shown in figure 4.5.\n",
    "\n",
    "![](images/4.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Adding a time dimension\n",
    "In the source data, each row is a separate hour of data (figure 4.5 shows a transposed\n",
    "version of this to better fit on the printed page). We want to change the row-per-hour\n",
    "organization so that we have one axis that increases at a rate of one day per index incre-\n",
    "ment, and another axis that represents the hour of the day (independent of the date).\n",
    "The third axis will be our different columns of data (weather, temperature, and so on).\n",
    "\n",
    "Let’s load the data (code/p1ch4/4_time_series_bikes.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy = np.loadtxt(\n",
    "    \"./data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])}) # Converts date strings to numbers corresponding to thebikes day of the month in column 1\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every hour, the dataset reports the following variables:\n",
    "* Index of record: `instant`\n",
    "* Day of month: `day`\n",
    "* Season: `season` ( `1` : spring, `2` : summer, `3` : fall, `4` : winter)\n",
    "* Year: `yr` ( `0` : 2011, `1` : 2012)\n",
    "* Month: `mnth` ( `1` to `12` )\n",
    "* Hour: `hr` ( `0` to `23` )\n",
    "* Holiday status: `holiday`\n",
    "* Day of the week: `weekday`\n",
    "* Working day status: `workingday`\n",
    "* Weather situation: `weathersit` ( `1` : clear, `2` :mist, `3` : light rain/snow, `4` : heavy rain/snow)\n",
    "* Temperature in °C: `temp`\n",
    "* Perceived temperature in °C: `atemp`\n",
    "* Humidity: `hum`\n",
    "* Wind speed: `windspeed`\n",
    "* Number of casual users: `casual`\n",
    "* Number of registered users: `registered`\n",
    "* Count of rental bikes: `cnt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a time series dataset such as this one, rows represent successive time-points: there is\n",
    "a dimension along which they are ordered. Sure, we could treat each row as indepen-\n",
    "dent and try to predict the number of circulating bikes based on, say, a particular time\n",
    "of day regardless of what happened earlier. However, the existence of an ordering\n",
    "gives us the opportunity to exploit causal relationships across time. For instance, it\n",
    "allows us to predict bike rides at one time based on the fact that it was raining at an\n",
    "earlier time. For the time being, we’re going to focus on learning how to turn our\n",
    "bike-sharing dataset into something that our neural network will be able to ingest in\n",
    "fixed-size chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Shaping the data by time period\n",
    "We might want to break up the two-year dataset into wider observation periods, like\n",
    "days. This way we’ll have N (for *number of samples*) collections of $C$ sequences of length $L$. In other words, our time series dataset would be a tensor of dimension 3 and shape $N × C × L$. The C would remain our 17 channels, while L would be 24: 1 per hour of\n",
    "the day. There’s no particular reason why we must use chunks of 24 hours, though the\n",
    "general daily rhythm is likely to give us patterns we can exploit for predictions. We\n",
    "could also use 7 × 24 = 168 hour blocks to chunk by week instead, if we desired. All of\n",
    "this depends, naturally, on our dataset having the right size—the number of rows must\n",
    "be a multiple of 24 or 168. Also, for this to make sense, we cannot have gaps in the\n",
    "time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s 17,520 hours, 17 columns. Now let’s reshape the data to have 3 axes—day, hour,\n",
    "and then our 17 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened here? First, `bikes.shape[1]` is 17, the number of columns in the\n",
    "`bikes` tensor. But the real crux of this code is the call to `view` , which is really important: it changes the way the tensor looks at the same data as contained in storage.\n",
    "\n",
    "For `daily_bikes` , the stride is telling us that advancing by 1 along the hour dimension (the second dimension) requires us to advance by 17 places in the storage (or one set of columns); whereas advancing along the day dimension (the first dimension) requires us to advance by a number of elements equal to the length of a row in the storage times 24 (here, 408, which is 17 × 24).\n",
    "\n",
    "We see that the rightmost dimension is the number of columns in the original dataset. Then, in the middle dimension, we have time, split into chunks of 24 sequential hours. In other words, we now have N sequences of L hours in a day, for C channels. To get to our desired N × C × L ordering, we need to transpose the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Ready for training\n",
    "The “weather situation” variable is ordinal. It has four levels: 1 for good weather, and 4\n",
    "for, er, really bad. We could treat this variable as categorical, with levels interpreted as labels, or as a continuous variable. If we decided to go with categorical, we would turn the variable into a one-hot-encoded vector and concatenate the columns with the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "first_day[:,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we scatter ones into our matrix according to the corresponding level at each\n",
    "row. Remember the use of `unsqueeze` to add a singleton dimension as we did in the\n",
    "previous sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(\n",
    "    dim=1,\n",
    "    index=first_day[:,9].unsqueeze(1).long() - 1,  # Decreases the values by 1 because weather situation ranges from 1 to 4, while indices are 0-based\n",
    "    value=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we concatenate our matrix to our original dataset using the cat function.\n",
    "Let’s look at the first of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have done the same with the reshaped `daily_bikes` tensor. Remember\n",
    "that it is shaped (B, C, L), where L = 24. We first create the zero tensor, with the same\n",
    "B and L, but with the number of additional columns as C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we scatter the one-hot encoding into the tensor in the C dimension. Since this\n",
    "operation is performed in place, only the content of the tensor will change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_( 1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we concatenate along the C dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned earlier that this is not the only way to treat our “weather situation” variable. Indeed, its labels have an ordinal relationship, so we could pretend they are special values of a continuous variable. We could just transform the variable so that it runs from 0.0 to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned in the previous section, rescaling variables to the [0.0, 1.0] interval\n",
    "or the [-1.0, 1.0] interval is something we’ll want to do for all quantitative variables,\n",
    "like `temperature` (column 10 in our dataset). We’ll see why later; for now, let’s just say\n",
    "that this is beneficial to the training process.\n",
    "\n",
    "There are multiple possibilities for rescaling variables. We can either map their\n",
    "range to [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "daily_bikes[:, 10, :] = (daily_bikes[:, 10, :] - temp_min)/(temp_max - temp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp)) / torch.std(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the latter case, our variable will have 0 mean and unitary standard deviation. If our\n",
    "variable were drawn from a Gaussian distribution, 68% of the samples would sit in the\n",
    "[-1.0, 1.0] interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Representing text\n",
    "Deep learning has taken the field of natural language processing (NLP) by storm, particularly using models that repeatedly consume a combination of new input and previous model output. These models are called *recurrent neural networks* (RNNs), and they have been applied with great success to text categorization, text generation, and automated translation systems. More recently, a class of networks called transformers with a more flexible way to incorporate past information has made a big splash. Previous NLP workloads were characterized by sophisticated multistage pipelines that included rules encoding the grammar of a language. 5 Now, state-of-the-art work trains networks end to end on large corpora starting from scratch, letting those rules emerge from the data. For the last several years, the most-used automated translation systems available as services on the internet have been based on deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Converting text to numbers\n",
    "There are two particularly intuitive levels at which networks operate on text: at the character level, by processing one character at a time, and at the word level, where individual words are the finest-grained entities to be seen by the network. The technique with which we encode text information into tensor form is the same whether we operate at the character level or the word level. And it’s not magic, either. We stumbled upon it earlier: one-hot encoding.\n",
    "\n",
    "Let’s load Jane Austen’s Pride and Prejudice from the Project Gutenberg website:\n",
    "www.gutenberg.org/files/1342/1342-0.txt. We’ll just save the file and read it in\n",
    "(code/p1ch4/5_text_jane_austen.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/p1ch4/jane-austen/1342-0.txt', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 One-hot-encoding characters\n",
    "There’s one more detail we need to take care of before we proceed: encoding. This is\n",
    "a pretty vast subject, and we will just touch on it. Every written character is represented\n",
    "by a code: a sequence of bits of appropriate length so that each character can be\n",
    "uniquely identified. The simplest such encoding is ASCII (American Standard Code\n",
    "for Information Interchange), which dates back to the 1960s. ASCII encodes 128 char-\n",
    "acters using 128 integers. For instance, the letter *a* corresponds to binary 1100001 or\n",
    "decimal 97, the letter *b* to binary 1100010 or decimal 98, and so on. The encoding fits\n",
    "8 bits, which was a big bonus in 1965.\n",
    "\n",
    "At this point, we need to parse through the characters in the text and provide a one-hot encoding for each of them. Each character will be represented by a vector of length equal to the number of different characters in the encoding. This vector will contain all zeros except a one at the index corresponding to the location of the character in the encoding.\n",
    "\n",
    "We first split our text into a list of lines and pick an arbitrary line to focus on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a tensor that can hold the total number of one-hot-encoded characters for\n",
    "the whole line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_t = torch.zeros(len(line), 128) # 128 hardcoded due to the limits of ASCII\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `letter_t` holds a one-hot-encoded character per row. Now we just have to\n",
    "set a one on each row in the correct position so that each row represents the correct\n",
    "character. The index where the one has to be set corresponds to the index of the character in the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0  # The text uses directional double quotes, which are not valid ASCII, so we screen them out here.\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 One-hot encoding whole words\n",
    "We’ll define `clean_words` , which takes text and returns it in lowercase and\n",
    "stripped of punctuation. When we call it on our “Impossible, Mr. Bennet” `line` , we get\n",
    "the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?”“_-'\n",
    "    word_list = input_str.lower().replace('\\n',' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list\n",
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s build a mapping of words to indexes in our encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7261, 3394)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
    "\n",
    "len(word2index_dict), word2index_dict['impossible']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `word2index_dict` is now a dictionary with words as keys and an integer as a\n",
    "value. We will use it to efficiently find the index of a word as we one-hot encode it.\n",
    "Let’s now focus on our sentence: we break it up into words and one-hot encode it that is, we populate a tensor with one one-hot-encoded vector per word. We create an\n",
    "empty vector and assign the one-hot-encoded values of the word in the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 3394 impossible\n",
      " 1 4305 mr\n",
      " 2  813 bennet\n",
      " 3 3394 impossible\n",
      " 4 7078 when\n",
      " 5 3315 i\n",
      " 6  415 am\n",
      " 7 4436 not\n",
      " 8  239 acquainted\n",
      " 9 7148 with\n",
      "10 3215 him\n",
      "torch.Size([11, 7261])\n"
     ]
    }
   ],
   "source": [
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))\n",
    "    \n",
    "print(word_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `tensor` represents one sentence of length 11 in an encoding space of size\n",
    "7,261, the number of words in our dictionary. Figure 4.6 compares the gist of our two\n",
    "options for splitting text (and using the embeddings we’ll look at in the next section).\n",
    "\n",
    "The choice between character-level and word-level encoding leaves us to make a\n",
    "trade-off. In many languages, there are significantly fewer characters than words: rep-\n",
    "resenting characters has us representing just a few classes, while representing words\n",
    "requires us to represent a very large number of classes and, in any practical applica-\n",
    "tion, deal with words that are not in the dictionary. On the other hand, words convey\n",
    "much more meaning than individual characters, so a representation of words is con-\n",
    "siderably more informative by itself. Given the stark contrast between these two\n",
    "options, it is perhaps unsurprising that intermediate ways have been sought, found,\n",
    "and applied with great success: for example, the byte *pair encoding method* starts with a\n",
    "dictionary of individual letters but then iteratively adds the most frequently observed\n",
    "pairs to the dictionary until it reaches a prescribed dictionary size. Our example sen-\n",
    "tence might then be split into tokens like this:\n",
    "\n",
    "?Im|pos|s|ible|,|?Mr|.|?B|en|net|,|?impossible|,|?when|?I|?am|?not|?acquainted|?with|?him\n",
    "\n",
    "![](images/4.5.png)\n",
    "<center>Figure 4.6 Three ways to encode a word</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 Text embeddings\n",
    "One-hot encoding is a very useful technique for representing categorical data in tensors. However, as we have anticipated, one-hot encoding starts to break down when the number of items to encode is effectively unbound, as with words in a corpus. In just one book, we had over 7,000 items!\n",
    "\n",
    "We certainly could do some work to deduplicate words, condense alternate spellings, collapse past and future tenses into a single token, and that kind of thing. Still, a\n",
    "general-purpose English-language encoding would be huge. Even worse, every time we encountered a new word, we would have to add a new column to the vector, which would mean adding a new set of weights to the model to account for that new vocabulary entry—which would be painful from a training perspective.\n",
    "\n",
    "How can we compress our encoding down to a more manageable size and put a cap on the size growth? Well, instead of vectors of many zeros and a single one, we can use vectors of floating-point numbers. A vector of, say, 100 floating-point numbers can indeed represent a large number of words. The trick is to find an effective way to map individual words into this 100-dimensional space in a way that facilitates downstream learning. This is called an __embedding__.\n",
    "\n",
    "In principle, we could simply iterate over our vocabulary and generate a set of 100 random floating-point numbers for each word. This would work, in that we could cram a very large vocabulary into just 100 numbers, but it would forgo any concept of distance between words based on meaning or context. A model using this word embedding would have to deal with very little structure in its input vectors. An ideal solution would be to generate the embedding in such a way that words used in similar contexts mapped to nearby regions of the embedding.\n",
    "\n",
    "Well, if we were to design a solution to this problem by hand, we might decide to\n",
    "build our embedding space by choosing to map basic nouns and adjectives along the axes. We can generate a 2D space where axes map to nouns—*fruit* (0.0-0.33), *flower* (0.33-0.66), and *dog* (0.66-1.0)—and adjectives—*red* (0.0-0.2), *orange* (0.2-0.4), *yellow* (0.4-0.6), *white* (0.6-0.8), and *brown* (0.8-1.0). Our goal is to take actual fruit, flowers, and dogs and lay them out in the embedding. \n",
    "\n",
    "As we start embedding words, we can map *apple* to a number in the *fruit* and *red* quadrant. Likewise, we can easily map *tangerine*, *lemon*, *lychee*, and *kiwi* (to round out our list of colorful fruits). Then we can start on flowers, and assign *rose*, *poppy*, *daffodil*, *lily*, and ... Hmm. Not many brown flowers out there. Well, *sunflower* can get *flower*, *yellow*, and *brown*, and then *daisy* can get *flower*, *white*, and *yellow*. Perhaps we should update *kiwi* to map close to *fruit*, *brown*, and *green*. For dogs and color, we can embed *redbone* near *red*; uh, *fox* perhaps for *orange*; *golden retriever* for *yellow*, *poodle* for *white*, and ... most kinds of dogs are *brown*.\n",
    "\n",
    "Now our embeddings look like figure 4.7. While doing this manually isn’t really feasible for a large corpus, note that although we had an embedding size of 2, we described 15 different words besides the base 8 and could probably cram in quite a few more if we took the time to be creative about it.\n",
    "\n",
    "![](images/4.6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the exact algorithms ([word2vec](https://code.google.com/archive/p/word2vec/)) used are a bit out of scope for what we’re wanting to focus on here, we’d just like to mention that embeddings are often generated using neural networks, trying to predict a word from nearby words (the context) in a sentence. In this case, we could start from one-hot-encoded words and use a (usually rather shallow) neural network to generate the embedding. Once the embedding was available, we could use it for downstream tasks.\n",
    "\n",
    "One interesting aspect of the resulting embeddings is that similar words end up not only clustered together, but also having consistent spatial relationships with other words. For example, if we were to take the embedding vector for apple and begin to add and subtract the vectors for other words, we could begin to perform analogies like apple- red - sweet + yellow + sour and end up with a vector very similar to the one for lemon.\n",
    "\n",
    "More contemporary embedding models—with **BERT** and **GPT-2** making headlines even in mainstream media—are much more elaborate and are context sensitive: that is, the mapping of a word in the vocabulary to a vector is not fixed but depends on the surrounding sentence. Yet they are often used just like the simpler classic embeddings we’ve touched on here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5 Text embeddings as a blueprint\n",
    "Embeddings are an essential tool for when a large number of entries in the vocabulary have to be represented by numeric vectors. We believe that how text is represented and processed can also be seen as an example for dealing with categorical data in general. Embeddings are useful wherever one-hot encoding becomes cumbersome. Indeed, in the form described previously, they are an efficient way of representing one-hot encoding immediately followed by multiplication with the matrix containing the embedding vectors as rows.\n",
    "\n",
    "When we are interested in co-occurrences of observations, the word embeddings we saw earlier can serve as a blueprint, too. For example, recommender systems—customers who liked our book also bought ...—use the items the customer already interacted with as the context for predicting what else will spark interest. Similarly, processing text is perhaps the most common, well-explored task dealing with sequences; so, for example, when working on tasks with time series, we might look for inspiration in what is done in natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Conclusion\n",
    "We’ve covered a lot of ground in this chapter. We learned to load the most common types of data and shape them for consumption by a neural network. Of course, there are more data formats in the wild than we could hope to describe in a single volume. Some,\n",
    "like medical histories, are too complex to cover here. Others, like audio and video, were deemed less crucial for the path of this book. If you’re interested, however, we provide short examples of audio and video tensor creation in bonus Jupyter Notebooks provided\n",
    "on the book’s website (www.manning.com/books/deep-learning-with-pytorch) and in our code repository (https://github.com/deep-learning-with-pytorch/dlwpt-code/tree/master/p1ch4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Exercises\n",
    "1. Take several pictures of red, blue, and green items with your phone or other digital camera (or download some from the internet, if a camera isn’t available).\n",
    "   * a. Load each image, and convert it to a tensor.\n",
    "   * b. For each image tensor, use the .mean() method to get a sense of how bright the image is.\n",
    "   * c. Take the mean of each channel of your images. Can you identify the red, green, and blue items from only the channel averages?\n",
    "2. Select a relatively large file containing Python source code.\n",
    "    * a. Build an index of all the words in the source file (feel free to make your toke- nization as simple or as complex as you like; we suggest starting with replacing r\"[^a-zA-Z0-9_]+\" with spaces).\n",
    "    * b. Compare your index with the one we made for Pride and Prejudice. Which is larger?\n",
    "    * c. Create the one-hot encoding for the source code file.\n",
    "    * d. What information is lost with this encoding? How does that information compare to what’s lost in the Pride and Prejudice encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
