{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BẮT ĐẦU NHANH\n",
    "Phần này sẽ giới thiệu toàn bộ các API phổ biến trong học máy (**machine learning**). Tham khảo các liên kết trong mỗi phần để tìm hiểu sâu hơn.\n",
    "## Làm việc với dữ liệu (Data)\n",
    "Pytorch có hai chương trình căn bản làm việc với data là `torch.utils.data.DataLoader` và `torch.utils.data.Dataset`. `Dataset` lưu các mẫu (**samples**) và nhãn (**labels**) tương ứng. `DataLoader` đóng gói một cách tuần tự xung quanh `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch cung cấp các thư viện dành riêng cho miền riêng biệt, chẳng hạn như [TorchText](https://pytorch.org/text/stable/index.html), [TorchVision](https://pytorch.org/vision/stable/index.html), và [TorchAudio](https://pytorch.org/audio/stable/index.html), tất cả đều bao gồm bộ dữ liệu. Đối với hướng dẫn này, chúng tôi sẽ sử dụng tập dữ liệu `TorchVision`.\n",
    "\n",
    "Mô-đun `torchvision.datasets` chứa các đối tượng `Dataset` cho nhiều dữ liệu trong thế giới thực như **CIFAR**, **COCO** ([danh sách đầy đủ tại đây](https://pytorch.org/vision/stable/datasets.html)). Trong hướng dẫn này, chúng tôi sử dụng tập dữ liệu **FashionMNIST**. Mỗi Tập dữ liệu `TorchVision` đều bao gồm hai đối số: `transform` và `target_transform` để sửa đổi các mẫu và nhãn tương ứng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta truyền `Dataset` làm đối số cho `DataLoader`. Điều này bao bọc một tệp có thể lặp lại trên tập dữ liệu của chúng ta và hỗ trợ tự động phân lô, lấy mẫu, xáo trộn và tải dữ liệu đa luồn. Ở đây chúng tôi xác định kích thước lô `batch_size=64`, tức là mỗi phần tử trong `dataloader` có thể lặp lại sẽ trả về một lô gồm 64 tính năng và nhãn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo Models\n",
    "Để định nghĩa mạng nơron trong PyTorch, chúng ta tạo một lớp kế thừa từ `nn.Module`. Chúng tôi xác định các layer của mạng trong hàm `__init__` và chỉ định cách dữ liệu sẽ truyền qua mạng trong hàm `forward`. Để tăng tốc các hoạt động trong mạng nơ-ron, chúng tôi chuyển nó sang GPU nếu có."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tối ưu thông số mô hình\n",
    "Để đào tạo một mô hình, chúng ta cần một hàm mất mát ([loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) và một bộ tối ưu hóa ([optimizer](https://pytorch.org/docs/stable/optim.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong một vòng lặp đào tạo duy nhất, mô hình đưa ra dự đoán trên tập dữ liệu đào tạo (được cung cấp cho tập dữ liệu đào tạo theo lô) và Lan truyền ngược (**backpropagates**) dự đoán để điều chỉnh thông số của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:5d}]\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng tôi cũng kiểm tra hiệu suất của mô hình dựa trên tập dữ liệu thử để đảm bảo nó đang học hỏi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quá trình đào tạo được thực hiện qua nhiều lần lặp lại (epoch). Trong mỗi epoch, mô hình học các thông số để đưa ra dự đoán tốt hơn. Chúng ta in độ chính xác (accuracy ) và mất mát (loss ) của mô hình ở mỗi epoch; chúng ta muốn thấy độ chính xác tăng lên và tổn thất giảm theo từng epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------\n",
      "loss: 2.300446 [    0/60000]\n",
      "loss: 2.287151 [ 6400/60000]\n",
      "loss: 2.280784 [12800/60000]\n",
      "loss: 2.279829 [19200/60000]\n",
      "loss: 2.263792 [25600/60000]\n",
      "loss: 2.272288 [32000/60000]\n",
      "loss: 2.255639 [38400/60000]\n",
      "loss: 2.252787 [44800/60000]\n",
      "loss: 2.251037 [51200/60000]\n",
      "loss: 2.233919 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.9%, Avg loss: 0.035045 \n",
      "\n",
      "Epoch 2\n",
      "------------------------\n",
      "loss: 2.232817 [    0/60000]\n",
      "loss: 2.207073 [ 6400/60000]\n",
      "loss: 2.189156 [12800/60000]\n",
      "loss: 2.203077 [19200/60000]\n",
      "loss: 2.170915 [25600/60000]\n",
      "loss: 2.194264 [32000/60000]\n",
      "loss: 2.164804 [38400/60000]\n",
      "loss: 2.161633 [44800/60000]\n",
      "loss: 2.171298 [51200/60000]\n",
      "loss: 2.128254 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 0.033456 \n",
      "\n",
      "Epoch 3\n",
      "------------------------\n",
      "loss: 2.132123 [    0/60000]\n",
      "loss: 2.087005 [ 6400/60000]\n",
      "loss: 2.045387 [12800/60000]\n",
      "loss: 2.084857 [19200/60000]\n",
      "loss: 2.026437 [25600/60000]\n",
      "loss: 2.045294 [32000/60000]\n",
      "loss: 1.997889 [38400/60000]\n",
      "loss: 1.983847 [44800/60000]\n",
      "loss: 2.031641 [51200/60000]\n",
      "loss: 1.949769 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.030857 \n",
      "\n",
      "Epoch 4\n",
      "------------------------\n",
      "loss: 1.959502 [    0/60000]\n",
      "loss: 1.916736 [ 6400/60000]\n",
      "loss: 1.845218 [12800/60000]\n",
      "loss: 1.920234 [19200/60000]\n",
      "loss: 1.850782 [25600/60000]\n",
      "loss: 1.871034 [32000/60000]\n",
      "loss: 1.800694 [38400/60000]\n",
      "loss: 1.797437 [44800/60000]\n",
      "loss: 1.877153 [51200/60000]\n",
      "loss: 1.778101 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 0.028308 \n",
      "\n",
      "Epoch 5\n",
      "------------------------\n",
      "loss: 1.786344 [    0/60000]\n",
      "loss: 1.755977 [ 6400/60000]\n",
      "loss: 1.662647 [12800/60000]\n",
      "loss: 1.765750 [19200/60000]\n",
      "loss: 1.702150 [25600/60000]\n",
      "loss: 1.733312 [32000/60000]\n",
      "loss: 1.646918 [38400/60000]\n",
      "loss: 1.655824 [44800/60000]\n",
      "loss: 1.749552 [51200/60000]\n",
      "loss: 1.662584 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.026368 \n",
      "\n",
      "Epoch 6\n",
      "------------------------\n",
      "loss: 1.646267 [    0/60000]\n",
      "loss: 1.636132 [ 6400/60000]\n",
      "loss: 1.522322 [12800/60000]\n",
      "loss: 1.651499 [19200/60000]\n",
      "loss: 1.591632 [25600/60000]\n",
      "loss: 1.634754 [32000/60000]\n",
      "loss: 1.543356 [38400/60000]\n",
      "loss: 1.558552 [44800/60000]\n",
      "loss: 1.661013 [51200/60000]\n",
      "loss: 1.590296 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.025046 \n",
      "\n",
      "Epoch 7\n",
      "------------------------\n",
      "loss: 1.547918 [    0/60000]\n",
      "loss: 1.556417 [ 6400/60000]\n",
      "loss: 1.427671 [12800/60000]\n",
      "loss: 1.573952 [19200/60000]\n",
      "loss: 1.516282 [25600/60000]\n",
      "loss: 1.567600 [32000/60000]\n",
      "loss: 1.475613 [38400/60000]\n",
      "loss: 1.496153 [44800/60000]\n",
      "loss: 1.598025 [51200/60000]\n",
      "loss: 1.542483 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 0.024138 \n",
      "\n",
      "Epoch 8\n",
      "------------------------\n",
      "loss: 1.478459 [    0/60000]\n",
      "loss: 1.501603 [ 6400/60000]\n",
      "loss: 1.363455 [12800/60000]\n",
      "loss: 1.520292 [19200/60000]\n",
      "loss: 1.463930 [25600/60000]\n",
      "loss: 1.518049 [32000/60000]\n",
      "loss: 1.428096 [38400/60000]\n",
      "loss: 1.451502 [44800/60000]\n",
      "loss: 1.550239 [51200/60000]\n",
      "loss: 1.508543 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.023464 \n",
      "\n",
      "Epoch 9\n",
      "------------------------\n",
      "loss: 1.425462 [    0/60000]\n",
      "loss: 1.459014 [ 6400/60000]\n",
      "loss: 1.315736 [12800/60000]\n",
      "loss: 1.480081 [19200/60000]\n",
      "loss: 1.425451 [25600/60000]\n",
      "loss: 1.479550 [32000/60000]\n",
      "loss: 1.391670 [38400/60000]\n",
      "loss: 1.417305 [44800/60000]\n",
      "loss: 1.510859 [51200/60000]\n",
      "loss: 1.481597 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 0.022926 \n",
      "\n",
      "Epoch 10\n",
      "------------------------\n",
      "loss: 1.381260 [    0/60000]\n",
      "loss: 1.424807 [ 6400/60000]\n",
      "loss: 1.277856 [12800/60000]\n",
      "loss: 1.447781 [19200/60000]\n",
      "loss: 1.395619 [25600/60000]\n",
      "loss: 1.448133 [32000/60000]\n",
      "loss: 1.361711 [38400/60000]\n",
      "loss: 1.388861 [44800/60000]\n",
      "loss: 1.476658 [51200/60000]\n",
      "loss: 1.459781 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.022476 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu models\n",
    "Một cách phổ biến để lưu một mô hình là tuần tự hóa từ điển trạng thái bên trong (chứa các tham số của mô hình)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Pytorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print(\"Save Pytorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tải models\n",
    "Quá trình tải một mô hình bao gồm tạo lại cấu trúc mô hình và tải từ điển trạng thái vào đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình này hiện có thể được sử dụng để đưa ra dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
