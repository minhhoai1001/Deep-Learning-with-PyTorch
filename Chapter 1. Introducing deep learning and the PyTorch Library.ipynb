{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducing deep learning and the PyTorch Library\n",
    "This chapter covers\n",
    "* How deep learning changes our approach to machine learning\n",
    "* Understanding why PyTorch is a good fit for deep learning\n",
    "* Examining a typical deep learning project\n",
    "* The hardware you’ll need to follow along with the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The deep learning revolution\n",
    "Deep learning, on the other hand, deals with finding such representations automatically, from raw data, in order to successfully perform a task. In the ones versus zeros example, filters would be refined during training by iteratively looking at pairs of examples and target labels. This is not to say that feature engineering has no place with deep learning; we often need to inject some form of prior knowledge in a learning system. However, the ability of a neural network to ingest data and extract useful representations on the basis of examples is what makes deep learning so powerful. The focus of deep learning practitioners is not so much on handcrafting those representations, but on operating on a mathematical entity so that it discovers representations from the training data autonomously. Often, these automatically created features are better than those that are handcrafted! As with many disruptive technologies, this fact has led to a change in perspective.\n",
    "\n",
    "On the right side of figure 1.1, we see a practitioner busy defining engineering features and feeding them to a learning algorithm; the results on the task will be as good as the features the practitioner engineers. On the left, with deep learning, the raw data is fed to an algorithm that extracts hierarchical features automatically, guided by the optimization of its own performance on the task; the results will be as good as the ability of the practitioner to drive the algorithm toward its goal.\n",
    "\n",
    "<img src=\"images/1.1.PNG\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the right side in figure 1.1, we already get a glimpse of what we need to execute successful deep learning:\n",
    "* We need a way to ingest whatever data we have at hand.\n",
    "* We somehow need to define the deep learning machine.\n",
    "* We must have an automated way, *training*, to obtain useful representations and make the machine produce desired outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PyTorch for deep learning\n",
    "PyTorch is a library for Python programs that facilitates building deep learning projects. It emphasizes flexibility and allows deep learning models to be expressed in idiomatic Python. This approachability and ease of use found early adopters in the\n",
    "research community, and in the years since its first release, it has grown into one of the most prominent deep learning tools across a broad range of applications. \n",
    "\n",
    "As Python does for programming, PyTorch provides an excellent introduction to deep learning. At the same time, PyTorch has been proven to be fully qualified for use in professional contexts for real-world, high-profile work. We believe that PyTorch’s clear syntax, streamlined API, and easy debugging make it an excellent choice for introducing deep learning. We highly recommend studying PyTorch for your first deep learning library. Whether it ought to be the last deep learning library you learn is a decision we leave up to you. \n",
    "\n",
    "This book is intended as a starting point for software engineers, data scientists, and motivated students fluent in Python to become comfortable using PyTorch to build deep learning projects. We want this book to be as accessible and useful as possible,\n",
    "and we expect that you will be able to take the concepts in this book and apply them to other domains. To that end, we use a hands-on approach and encourage you to keep your computer at the ready, so you can play with the examples and take them a step further. By the time we are through with the book, we expect you to be able to take a data source and build out a deep learning project with it, supported by the excellent official documentation.\n",
    "\n",
    "In order to get the most out of this book, you will need two things:\n",
    "* Some experience programming in Python. We’re not going to pull any punches on that one; you’ll need to be up on Python data types, classes, floating-point numbers, and the like.\n",
    "* A willingness to dive in and get your hands dirty. We’ll be starting from the basics and building up our working knowledge, and it will be much easier for you to learn if you follow along with us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Why PyTorch?\n",
    "As we’ve said, deep learning allows us to carry out a very wide range of complicated tasks, like machine translation, playing strategy games, or identifying objects in cluttered scenes, by exposing our model to illustrative examples. In order to do so in practice, we need tools that are flexible, so they can be adapted to such a wide range of problems, and efficient, to allow training to occur over large amounts of data in reasonable times; and we need the trained model to perform correctly in the presence of variability in the inputs. Let’s take a look at some of the reasons we decided to use PyTorch.\n",
    "\n",
    "PyTorch is easy to recommend because of its simplicity. Many researchers and practitioners find it easy to learn, use, extend, and debug. It’s Pythonic, and while like any complicated domain it has caveats and best practices, using the library generally feels familiar to developers who have used Python previously.\n",
    "\n",
    "More concretely, programming the deep learning machine is very natural in PyTorch. PyTorch gives us a data type, the `Tensor`, to hold numbers, vectors, matrices, or arrays in general. In addition, it provides functions for operating on them. We can program with them incrementally and, if we want, interactively, just like we are used to from Python. If you know NumPy, this will be very familiar.\n",
    "\n",
    "But PyTorch offers two things that make it particularly relevant for deep learning: first, it provides accelerated computation using graphical processing units (GPUs), often yielding speedups in the range of 50x over doing the same calculation on a CPU. Second, PyTorch provides facilities that support numerical optimization on generic mathematical expressions, which deep learning uses for training. Note that both features are useful for scientific computing in general, not exclusively for deep learning. In fact, we can safely characterize PyTorch as a high-performance library with optimization support for scientific computing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 The deep learning competitive landscape\n",
    "While all analogies are flawed, it seems that the release of PyTorch 0.1 in January 2017 marked the transition from a Cambrian-explosion-like proliferation of deep learning libraries, wrappers, and data-exchange formats into an era of consolidation and unification.\n",
    "\n",
    "At the time of PyTorch’s first beta release:\n",
    "* Theano and TensorFlow were the premiere low-level libraries, working with a model that had the user define a computational graph and then execute it.\n",
    "* Lasagne and Keras were high-level wrappers around Theano, with Keras wrapping TensorFlow and CNTK as well.\n",
    "* Caffe, Chainer, DyNet, Torch (the Lua-based precursor to PyTorch), MXNet, CNTK, DL4J, and others filled various niches in the ecosystem.\n",
    "\n",
    "In the roughly two years that followed, the landscape changed drastically. The community largely consolidated behind either PyTorch or TensorFlow, with the adoption of other libraries dwindling, except for those filling specific niches. In a nutshell:\n",
    "* Theano, one of the first deep learning frameworks, has ceased active development.\n",
    "* TensorFlow:\n",
    "    * Consumed Keras entirely, promoting it to a first-class API\n",
    "    * Provided an immediate-execution “eager mode” that is somewhat similar to how PyTorch approaches computation\n",
    "    * Released TF 2.0 with eager mode by default\n",
    "* JAX, a library by Google that was developed independently from TensorFlow, has started gaining traction as a NumPy equivalent with GPU, autograd and JIT capabilities.\n",
    "* PyTorch:\n",
    "    * Consumed Caffe2 for its backend\n",
    "    * Replaced most of the low-level code reused from the Lua-based Torch project\n",
    "    * Added support for ONNX, a vendor-neutral model description and exchange format\n",
    "    * Added a delayed-execution “graph mode” runtime called TorchScript\n",
    "    * Released version 1.0\n",
    "    * Replaced CNTK and Chainer as the framework of choice by their respective corporate sponsors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 An overview of how PyTorch supports deep learning projects\n",
    "First, PyTorch has the “Py” as in Python, but there’s a lot of non-Python code in it. Actually, for performance reasons, most of PyTorch is written in C++ and [CUDA](www.geforce.com/hardware/technology/cuda), a C++-like language from NVIDIA that can be compiled to run with massive parallelism on GPUs. There are ways to run PyTorch directly from C++, and we’ll look into those in chapter 15. One of the motivations for this capability is to provide a reliable strategy for deploying models in production.\n",
    "However, most of the time we’ll interact with PyTorch from Python, building models, training them, and using the trained models to solve actual problems.\n",
    "\n",
    "As we already touched on, at its core, PyTorch is a library that provides **multidimensional arrays**, or `tensors` in PyTorch parlance (we’ll go into details on those in chapter3), and an extensive library of operations on them, provided by the `torch` module. Both tensors and the operations on them can be used on the CPU or the GPU. Moving computations from the CPU to the GPU in PyTorch doesn’t require more than an additional function call or two. The second core thing that PyTorch provides is the\n",
    "ability of tensors to keep track of the operations performed on them and to analytically compute derivatives of an output of a computation with respect to any of its inputs. This is used for numerical optimization, and it is provided natively by tensors\n",
    "by virtue of dispatching through PyTorch’s `autograd` engine under the hood.\n",
    "\n",
    "The core PyTorch modules for building neural networks are located in `torch.nn`, which provides common neural network layers and other architectural components. Fully connected layers, convolutional layers, activation functions, and loss functions\n",
    "can all be found here (we’ll go into more detail about what all that means as we go through the rest of this book). These components can be used to build and initialize the untrained model we see in the center of figure 1.2. In order to train our model, we need a few additional things: a source of training data, an optimizer to adapt the model to the training data, and a way to get the model and data to the hardware that will actually be performing the calculations needed for training the model.\n",
    "\n",
    "<img src=\"images/1.2.PNG\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Summary\n",
    "* Deep learning models automatically learn to associate inputs and desired outputs from examples.\n",
    "* Libraries like PyTorch allow you to build and train neural network models efficiently.\n",
    "* PyTorch minimizes cognitive overhead while focusing on flexibility and speed. It also defaults to immediate execution for operations.\n",
    "* TorchScript allows us to precompile models and invoke them not only from Python but also from C++ programs and on mobile devices.\n",
    "* Since the release of PyTorch in early 2017, the deep learning tooling ecosystem has consolidated significantly.\n",
    "* PyTorch provides a number of utility libraries to facilitate deep learning projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
